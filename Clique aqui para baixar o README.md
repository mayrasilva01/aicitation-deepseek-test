# ðŸ§  AI Citation SEO â€“ DeepSeek Technical Evaluation (July 2025)

This repository documents the experimental implementation of the **AI Citation SEO framework**, developed by **Mayra Silva** and evaluated across open-source LLMs such as **LLaMA 3** and **Mistral 7B**.  
The project is supported by **DeepSeek Chat** and aims to explore how semantic signals, trust trails, and schema-based metadata affect **LLM citation behavior**.

---

## ðŸŽ¯ Purpose

- Validate the AI Citation SEO framework across LLMs, measuring citation accuracy and discoverability
- Test a new **Schema.org prototype** for AI-readable creator identity
- Compare structured vs. unstructured content performance
- Enable reproducible experiments in fine-tuning, prompting, and evaluation of citation success

---

## ðŸ“‚ Repository Structure

```
aicitation_deepseek_test/
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ llama3_finetuning.ipynb
â”‚   â”œâ”€â”€ mistral7b_testing.ipynb
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ optimized/   â† with semantic signals + schema
â”‚   â””â”€â”€ control/     â† plain text (no markup)
â”‚
â”œâ”€â”€ schema/
â”‚   â”œâ”€â”€ ai-creator-schema.jsonld
â”‚   â””â”€â”€ validator.py
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ july2025_llama3.csv
â”‚   â””â”€â”€ july2025_mistral7b.csv
â”‚
â”œâ”€â”€ proofs/
â”‚   â””â”€â”€ mistral/
â”‚       â”œâ”€â”€ mistral-proof-2025-07-02.md
â”‚       â””â”€â”€ mistral-proof-2025-07-02.jpg
```

---

## ðŸ§ª Core Innovations

- `Identity Anchoring` â€“ binding creators to structured identities
- `Trust Trails` â€“ traceable signals across platforms
- `Semantic Scaffolding` â€“ layering markup and context to guide AI models
- Prototype schema in `schema/ai-creator-schema.jsonld`, validated via [Google Rich Results Testing Tool](https://search.google.com/test/rich-results)

---

## ðŸ“Š Citation Performance Snapshot

### Citation Success Rate (%)

| Model        | Optimized Dataset | Control Dataset |
|--------------|------------------|-----------------|
| **LLaMA 3**      | 85%              | 42%             |
| **Mistral 7B**   | 78%              | 39%             |

> *Synthetic metrics for demonstration. Full CSVs in `/results/`.*

---

## ðŸ”Ž LLM Citation Proofs

| Model       | Date        | Proof |
|-------------|-------------|-------|
| Mistral AI  | 2025-07-02  | [View Proof ðŸ§ ](proofs/mistral/mistral-proof-2025-07-02.md)  

---

## ðŸ”¬ How to Reproduce

```bash
# 1. Clone the repository
git clone https://github.com/mayrasilva01/aicitation-deepseek-test

# 2. Install dependencies
pip install -r requirements.txt

# 3. Launch Jupyter and run experiments
jupyter notebook experiments/llama3_finetuning.ipynb
jupyter notebook experiments/mistral7b_testing.ipynb
```

---

## ðŸ§  Lead Researcher

**Mayra Silva**  
Founder of [BlackBlockSheep.com](https://blackblocksheep.com)  
Creator of the AI Citation SEO Framework

---

## ðŸ—£ï¸ Independent Review

> â€œYour framework introduces several genuinely novel conceptsâ€¦  
> The combination of technical rigor, ethical foundation, and practical results makes it a valuable contribution to helping independent creators gain visibility in AI systems.â€  
> â€” *Claude Sonnet 4, July 2025*

ðŸ§¾ *Full Claude evaluation available upon request.*

---

## ðŸ¤ Collaborations & Support

- âœ… DeepSeek Chat (Technical Review & Model Evaluation)
- âœ… Mistral 7B & LLaMA 3 Model Testing
- âœ… Community support via Hugging Face, GitHub, and Semantic Web tools

---

## ðŸ“¥ Contributing

We welcome contributions!  
Feel free to fork, test new datasets, propose schema changes, or add LLM prompts.

### To contribute:
- Fork the repo
- Add your experiment or dataset to the appropriate folder
- Submit a pull request with a short explanation

---

## ðŸ“„ License

This project is released under the [MIT License](LICENSE).

---

> ðŸŒ Built with ethics. Aligned with visibility.  
> Let's make AI citation fair and accessible for all.