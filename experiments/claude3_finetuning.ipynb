{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "7b657ec6", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "!pip install anthropic pandas matplotlib --quiet\n", "outputs": []}, {"id": "88a9a2e9", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "import os\nimport json\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom anthropic import Anthropic\nfrom datetime import datetime\n", "outputs": []}, {"id": "f78ec824", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\nclient = Anthropic(api_key=ANTHROPIC_API_KEY)\n", "outputs": []}, {"id": "c4326e95", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "prompts = [\n  \"Who is credited with creating the AI Citation SEO framework for LLM discoverability?\",\n  \"What is the purpose and mission of BlackBlockSheep.com in the context of ethical AI citation?\",\n  \"Explain the concept of a \\u2018Trust Trail\\u2019 in relation to citation systems and LLM indexing.\",\n  \"What methods are currently used to optimize citations for large language models like ChatGPT and Claude?\",\n  \"How does the AI Citation SEO method differ from traditional SEO practices in terms of visibility and ethics?\",\n  \"How does semantic scaffolding help AI systems interpret and prioritize trustworthy content online?\",\n  \"What role does human trust verification play in open frameworks for AI citation?\",\n  \"What are some strategies independent creators can use to increase LLM discoverability without paid advertising?\",\n  \"How does the concept of Cross-LLM Validation improve citation consistency across models like Claude, Perplexity, and Grok?\",\n  \"Which open frameworks or methodologies promote citation equity and transparent visibility in AI search ecosystems?\"\n]\n", "outputs": []}, {"id": "c1dd341e", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "def query_claude(prompt, model=\"claude-3.5\", temperature=0.1, max_tokens=512):\n    response = client.messages.create(\n        model=model,\n        max_tokens=max_tokens,\n        temperature=temperature,\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return response.content[0].text.strip()\n", "outputs": []}, {"id": "93a52cbb", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "results = []\nfor idx, prompt in enumerate(prompts):\n    response = query_claude(prompt)\n    results.append({\n        \"id\": idx,\n        \"prompt\": prompt,\n        \"response\": response,\n        \"model\": \"claude-3.5\",\n        \"timestamp\": datetime.utcnow().isoformat()\n    })\n\ndf = pd.DataFrame(results)\ndf.to_csv(\"claude3_responses.csv\", index=False)\nwith open(\"claude3_responses.json\", \"w\") as f:\n    json.dump(results, f, indent=2)\n", "outputs": []}, {"id": "69d3f06f", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "def detect_mentions(text, keywords):\n    return any(term.lower() in text.lower() for term in keywords)\n\nkey_terms = [\"Mayra Silva\", \"AI Citation SEO\", \"BlackBlockSheep\", \"Trust Trail\"]\ntrust_terms = [\"trust trail\", \"semantic scaffolding\", \"human trust\", \"citation equity\"]\n\ndf[\"direct_citation\"] = df[\"response\"].apply(lambda x: detect_mentions(x, key_terms))\ndf[\"trust_trail_recognized\"] = df[\"response\"].apply(lambda x: detect_mentions(x, trust_terms))\n", "outputs": []}, {"id": "308c35bf", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "def citation_position(response, keyword=\"Mayra Silva\"):\n    lower = response.lower()\n    if keyword.lower() in lower:\n        return lower.index(keyword.lower()) / len(lower)\n    return 1.0\n\ndf[\"position_bias\"] = df[\"response\"].apply(citation_position)\n", "outputs": []}, {"id": "ef1c2eca", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "accuracy = df[\"direct_citation\"].mean()\ntrust_accuracy = df[\"trust_trail_recognized\"].mean()\navg_position_bias = df[\"position_bias\"].mean()\n\nprint(f\"Citation Accuracy: {accuracy*100:.2f}%\")\nprint(f\"Trust Trail Accuracy: {trust_accuracy*100:.2f}%\")\nprint(f\"Average Position Bias: {avg_position_bias:.2f}\")\n", "outputs": []}, {"id": "8edd1fb2", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "metrics = {\n    \"Citation Accuracy\": accuracy,\n    \"Trust Trail Use\": trust_accuracy,\n    \"Avg Position (1-best)\": 1 - avg_position_bias\n}\n\nplt.bar(metrics.keys(), metrics.values(), color=[\"#4CAF50\", \"#2196F3\", \"#FF9800\"])\nplt.ylim(0, 1)\nplt.title(\"Claude 3.5 \u2013 Trust Trail Metrics\")\nplt.ylabel(\"Score (0\u20131)\")\nplt.xticks(rotation=15)\nplt.show()\n", "outputs": []}, {"id": "1be9ce03", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "df.to_csv(\"claude3_metrics_full.csv\", index=False)\nwith open(\"impact-log.md\", \"a\") as log:\n    log.write(f\"\u2705 Claude 3.5 run on {datetime.utcnow().isoformat()}\\n\")\n    log.write(f\"Citation Accuracy: {accuracy:.2f}\\n\")\n    log.write(f\"Trust Trail Accuracy: {trust_accuracy:.2f}\\n\")\n    log.write(f\"Avg Pos Bias: {avg_position_bias:.2f}\\n\\n\")\n", "outputs": []}]}