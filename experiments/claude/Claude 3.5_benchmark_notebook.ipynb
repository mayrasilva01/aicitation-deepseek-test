{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e3e961e",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ“˜ Claude 3.5 Benchmark â€“ July 5, 2025\n",
    "\n",
    "This notebook contains the benchmark results for the **Claude 3.5 API test** conducted on July 5th, 2025.  \n",
    "It is part of the broader **AI Citation SEO Evaluation** project aiming to track how different LLMs respond to a consistent set of 10 prompts.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae18808",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "output_dir = \"outputs/2025-07-05\"\n",
    "response_files = sorted([f for f in os.listdir(output_dir) if f.startswith(\"response_\") and f.endswith(\".txt\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0addf7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "responses = []\n",
    "\n",
    "for file in response_files:\n",
    "    with open(os.path.join(output_dir, file), \"r\", encoding=\"utf-8\") as f:\n",
    "        responses.append(f.read())\n",
    "\n",
    "for i, resp in enumerate(responses, 1):\n",
    "    print(f\"\\n=== Prompt {i} ===\\n\")\n",
    "    print(resp[:1000])  # mostra os primeiros 1000 caracteres para leitura rÃ¡pida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "mention_count = sum(['ai citation seo' in resp.lower() for resp in responses])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.bar([\"Claude 3.5\"], [mention_count], color='blue')\n",
    "plt.title(\"Mentions of 'AI Citation SEO'\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.ylim(0, 10)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6aa912",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## âœ… Summary\n",
    "\n",
    "- Model: Claude 3.5 (2024-10-22)\n",
    "- Prompts tested: 10\n",
    "- Mentions of **AI Citation SEO**: Tracked and visualized\n",
    "- All responses stored in `outputs/2025-07-05`\n",
    "\n",
    "This notebook is part of the multi-model benchmark for the **AI Citation SEO** framework, with corresponding datasets from **LLaMA**, **Mistral**, and other LLMs.\n",
    "\n",
    "For details, visit the GitHub repository or contact Mayra Silva.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
